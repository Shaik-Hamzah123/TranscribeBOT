 We're building here at XAI and we've been working extremely hard over the last few months to improve Grok as much as we can. So we can give it to all of you, so we can give all of you access to it. We think it's going to be extremely useful. We think it's going to be interesting to talk to a funny, really, really funny. And we're going to explain to you how we've improved Grok over the last few months. We've made quite a jump in capabilities. Actually, we should explain maybe also why do we call it Grok. So Grok is a word from a Heinlein novel, Stranger in a Strange Land. and it's used by a guy who was raised on Mars and the word grok is to sort of fully and profoundly understand something. That's what the word grok means, fully and profoundly understand something. And empathy is important. True. Yeah. So, yeah, so if we charted XAS progress in the last few months, it's only been 17 months since we started kicking off our very first model, Grok 1 was almost like a toy by this point, only 214 billion parameters. And now if we're proud to progress, the time on the x-axis, the performance of favorite benchmark numbers, MMLU on the y-axis, we're literally progressing at unprecedented speed across the whole field. And then we kick off Grok 1.5 right after Grok 1, released after November 2023. then grog2. So if you look at where all the performance coming from, we have a very correct engineering team and all the best AI talent, there's only one thing we need is a big intelligence comes from big cluster. So we can reconvert the entire progress of XAI now replacing the benchmark on the y-axis to the total amount of training flops. That is, how many GPUs we can run at any given time to train our large language models to compress the entire Internet. So after Grok 2... All human knowledge, really. That's right. Yeah, Internet being part of it, but it's really all human knowledge, everything. Yeah, the whole Internet fits into a USB stick at this point. It's like all the human tokens, yeah. That's right. Yeah. Very soon into the real world. Yeah. So we had so much trouble actually training Grok2 back in the days. We kicked off the model around February and we thought we had a large amount of chips but it turned out we can barely get 8K training chips running coherently at any given time. And we had so many cooling and power issues. I think you were there in the data center. Yeah, it was like really sort of more like 8k TÜVs on average at 80% efficiency, more like 6,500 effective H100s training for several months. But now we're at 100k. Yeah, that's right. More than 100k. That's right. So what's the next step? So after Gwag 2, if we want to continue to accelerate, we have to take the matter into our own hands. We have to solve all the coolings, all the power issues, and everything. So in April of last year, Elon decided that really the only way for XAI to succeed, for XAI to build the best AI out there, is to build our own data center. So we didn't have a lot of time, because we wanted to give you GoCree as quickly as possible. So really, we realized we have to build the data center in about four months. it turned out it took us 122 days to get the first 100k gpus up and running and that was a monumental effort to be able to do that it's we believe it's the biggest fully connected h100 cluster of its kind and we didn't just stop there we actually decided that we need to double the size of the cluster pretty much immediately if we want to build the kind of ai that we want to build So we then had another phase, which we haven't talked about publicly yet, so this is the first time that we're talking about this, where we doubled the capacity of the data center yet again, and that one only took us 92 days. So we've been able to use all of these GPUs, use all of this compute to improve Grok in the meantime, and basically today we're going to present you the results of that, the fruits that came from that. That's great. Yeah, so all the paths, all the rows leads to Grok 3. 10x more compute. More than 10x, really. Yeah, really. Maybe 15x-ish. Yep, compared to our previous generation model. And Grok 3 finished pre-training early January. And the model is still currently training, actually. So this is a little preview of our benchmark numbers. so we evaluate the Grok-3 on three different categories, general mathematical reasoning, general knowledge about STEM and science, and then also computer science, coding. So AMI, American Invitational Math Examination, hosts it once a year. And if we evaluate the model performance, we can see that the Grok 3 across the board is in a league of its own. Even its little brother, Grok 3 Mini, is reaching the frontier across all the other competitors. So you would say, well, at this point, all these benchmarks, you're just evaluating the memorization of the textbooks, memorization of the GitHub repos. How about a real-time usefulness? How about we actually use those models in our product? So what we did instead is we actually kicked off a blind test of our graphic model, codenamed chocolate. It's pretty hot. Yeah, hot chocolate. And, you know, been running on this platform called Chabot Arena for two weeks. I think the entire X platform at some point speculated this might be the next generation of AI coming your way. So how this chatbot arena works is that it strips away the entire product surface. It's just raw comparison of the engine of those AGI's, the language models themselves, and place interface where the user will submit one single query and you get to show two responses You don know which model they come from and in the end you make the vote So in the Spline test Grok 3 an early version of Grok 3 already reached like 1400. No other models has reached an ELO score. Had to have comparison to all the other models at this score. And it's not just one single category. It's 1400 aggregated across all the categories. In chatbot capabilities, in tracking following, coding. So it's number one across the board in this blind test. And it's still climbing, so we actually have to keep updating it. So it's about 1,400 and climbing. In fact, we have a version of the model that we think is already much better than the one that we tested here. We'll see how far it gets, but that's the one that we're working on, we're talking about today. Yeah, so actually one thing, if you're using Brock 3, I think you may notice improvements almost every day because we're continuously improving the model. So literally, even within 24 hours, you'll see improvements. Yep. But we believe here at XAI, getting the best pre-training model is not enough. That's not enough to build the best AI. And the best AI needs to think like a human. It'll contemplate about all the possible solutions, self-critique, verify all the solutions, backtrack and also think from the first principle that's a very important capability so we believe that as we take the best pre-trained model and continue training it with reinforcement learning it will enlist the additional reasoning capabilities that allows the model to become so much better and scale not just in the training time but actually in the test time as well so we already found the model is extremely useful internally for our own engineering, saving hours of time, hundreds of hours of coding time. So Igor, you are the power user of our graph reasoning model. What are some use cases? Yes, so like Jimmy said, we've added advanced reasoning capabilities to Grok and we've been testing them pretty heavily over the last few weeks in order to give you a little bit of a taste of what it looks like when Grok is solving hard reasoning problems. So we've prepared two little problems for you. One comes from physics and one is actually a game that Grog is going to write for us. So when it comes to the physics problem, what we want Grog to do is to plot a viable trajectory to do a transfer from Earth to Mars and then at a later point in time, a transfer back from Mars to Earth. And that requires some physics that Grog will have to understand. So we're going to challenge Grog, come up with a viable trajectory, calculate it, and and then plot it for us so we can see it. And yeah, this is totally unscripted, by the way. Yeah, that's the entirety of the prompt, which we should clarify, is that there's nothing more than that. Yeah, exactly. This is the Grok interface, and we've typed in this text that you can see here, generate code for an animated 3D plot of a launch from Earth, landing on Mars, and then back to Earth at the next launch window. And we've now kicked off the query, and you can see Grok is thinking. So part of Grok's advanced reasoning capabilities are these thinking traces that you can see here. You can even go inside and actually read what Grok is thinking as it's going through the problem, as it's trying to solve it. Yeah, we are doing some obscuration of the thinking so that our model doesn't get totally copied instantly. So there's more to the thinking than is displayed. Yeah. Yeah. And because this is totally unscripted, there's actually a chance that Grok might make a little coding mistake and it might not actually work. So just in case, we're going to launch two more instances of this. So if something goes wrong, we'll be able to switch to those and show you something that's presentable. So we're kicking off the other two as well. And like I said, we have a second problem as well. And yeah, actually one of our favorite activities here at XCI is having Grog write games for us. And not just any old game, any game that you might already be familiar with, but actually creating new games on the spot and being creative about it. So one example that we found was really, really fun is create a game that's a mixture of the two games Tetris and Bejeweled. This is maybe an important thing. like this obviously if you if you ask an AI to create a game like Tetris there's there are many examples of Tetris on the on the internet that ever or you game like to build whatever this it can copy it what's interesting here is it achieved a creative solution combining the two games that actually works and it's and is a good game yeah that's the it's created we're seeing the beginnings of creativity yeah fingers crossed that we can recreate that hopefully it works Yeah, yeah. It would be embarrassing if it doesn't. So actually, because this is a bit more challenging, we're going to use something special here, which we call Big Brain. That's our mode in which we use more computation, which is more reasoning for Brock, just to make sure that there's a good chance here that it might actually do it. So we're also going to fire off three attempts here at solving this game, at creating this game that's a mixture of Tetris and Bejeweled. Let's see what Brock comes up with. I've played the game, it's pretty good. Like, it's, like, wow, okay, this is something. Yeah. So while Greg is thinking, in the background, we can now actually talk about some concrete numbers, how well is Greg doing across tons of different tasks that we've tested it on. So we'll hand it over to Tony to talk about that. Yeah, okay, so let's see how Greg does on those interesting, challenging benchmarks. So, yeah, so reasoning, again, refers to those models that actually thinks for quite a long time before it tries to solve a problem. So in this case, around a month ago, the graph 3 pre-training finished. So after that, we worked very hard to put the reasoning capability into the current graph 3 model. But again, this is very early days, so the model is still currently in training. So right now, what we're going to show to people is this beta version of the graph 3 reasoning model. Alongside, we also are training a mini version of the reasoning model. So essentially on this plot you can see the graph three reasoning beta and then graph three mini reasoning The graph three mini reasoning is actually a model that we train for much longer time and you can see that sometimes you actually perform slightly better compared to the graph three reasoning this also just means that there's a huge potential for the graph three reasoning because it's trained for much less time so alright so let's actually look at what how it does on those three benchmarks so Jimmy also introduced already so essentially we're looking at three different areas mathematics science and coding and for math we're taking this high school competition as from for science we actually pick those PhD level science questions and for coding it's also actually pretty challenging it's competitive coding and also some Nicole which is some code interview problems that people usually get when they interview for companies so on those benchmarks you can see that the graph three actually perform quite well across the board compared to other competitors yeah so it's pretty promising these models are very smart so Tony what what are those shaded bars yeah so okay so I'm glad you asked this question so for those models because it can reason it can things you can also ask them to even think longer you can spend more what we call test and compute which means you can spend more time to reason to think about a problem before you spit out the answer so in this case the shaded bar here means that we just asked the model to spend more more time you know you can solve the same problem many many times before it tries to conclude what is the right solution and once you give this compute or this this kind of budget to the model it turns out the model can even perform better. So this is essentially the shaded part in the Windows Plus. Right, so I think this is really exciting right because now instead of just doing one chain of thoughts with AI, why not do multiple all at once? So that's a very powerful technique that allows to continue scale the model capabilities after training and you know people often ask are we actually just overfitting to the benchmarks? So how about your organization? So yes I think Yeah, this is definitely a question that we are asking ourselves, whether we are overfitting to those current benchmarks. Luckily, we have a real test. So about five days ago, AIME 2025 just finished. This is where high school students compete in this particular benchmark. So we got this very fresh new competition, and then we asked our two models to compete on the same benchmark, on the same exam. It turns out, very interestingly, the graph-free reasoning, the big one, actually does better on this particular new fresh exam. This also means that the generalization capability of the big model is stronger, much stronger, compared to the smaller model. If you compare it to last year's exam, actually this is the opposite. The smaller model kind of learns the previous exams better. So this actually shows some kind of true generalization from the model. That's right. So 17 months ago, our Grok 0 and Grok 1 barely solved any high school problems. That's right. And now we have a kid that just already graduated. The Grok is ready to go to college. Is that right? Yeah. I mean, it won't be long before it's simply perfect. The human exams won't be too easy. Yeah. And internally, we actually, as the Grok continue to evolve, we're going to talk about what we're excited about, but very soon there will be no more benchmarks left. Yeah. Yeah, one thing that's quite fascinating, I think, is that we basically only trained Grok's reasoning abilities on math problems and competitive coding problems. So very, very specialized kinds of tasks, but somehow it's able to work on all kinds of other different tasks, so including creating games, no, lots and lots of different things. And what seems to be happening is that basically Grok learns this ability to detect its own mistakes in its thinking, correct them, persist on a problem, try lots of different variants, pick the one that's best. So there are these generalizing abilities that Grok learns from mathematics and from coding, which it can then use to solve all kinds of other problems. So that's pretty... Reality is the instantiation of mathematics. That's right. And one thing we're actually really excited about, going back to our founding mission, is what if one day we have a computer just like Deep Thought, that utilize our entire cluster just for that one very important problem in the test time. And all the GPU turned on, right? So I think back then we were building the GPU clusters together. You were plugging cables. And I remember that when we turned on the first initial test, you could hear all the GPUs humming in the hallway. That almost felt like spiritual. Yeah, that's actually a pretty cool thing that we're able to do, that we can go into the data center and tinker with the machines there. So, for example, we went in and we unplugged a few of the cables and just made sure that our training setup is still running stably. So that's something that I think most AI teams out there don't usually do, but it actually totally unlocks a new level of reliability and what you're able to do with the hardware. Okay, so when are we going to solve Remon? So the easiest solution is to numerate over all possible strings. And as long as you have a verifier and enough compute, you'll be able to do it. My projection would be... What's your guess? What does your neural net calculate? So my bold prediction, so three years ago I told you this. I think now it's two years later, two things are going to happen. We're going to see machines win some medals. Yes. Turing's Award, Fields Medal, Nobel Prize, with probably some expert in the loop, right? So the expert uplifting. So this year or next year? Oh, okay. That's what it comes down to, really. So it looks like Grok finished all of his thinking on the two problems. So let's take a look at what it said. All right, so this was the little physics problem we had. No, we've collapsed the thoughts here. so they're hidden. And then we see Grok's answer below that, so it explains, it wrote a Python script here using matplotlib then gives us all of the code So let take a quick look at the code Seems like it doing reasonable things here not totally off the mark Solve Kepler says here so maybe it solving Kepler laws numerically There's really only one way to find out if this thing is working. I'd say let's give it a try. Let's run the code. And we can see Grok is animating two different planets, Earth and Mars here, and then the green ball is the vehicle that's transiting, the spacecraft that's transitioning between Earth and Mars. And you could see the journey from Earth to Mars, and it looks like, yeah, indeed the astronauts returned safely, you know, at the right moment in time. So, obviously this was just generated on the spot, so we can't tell you if that was actually a correct solution, so we're going to take a closer look, and maybe we're going to call some colleagues at SpaceX ask them if this is and Starship rockets to Mars we gotta we gotta run this to figure out if it's working the Tetris as we named it I mean it activates and coding interpreters that builds the foundations and the best reasoning model those are foundations only a lot of models to think harder these be using a model right so we already see that we actually give the capability for those model to think harder, think longer, think more broad, the performance continue to improve. And we're really excited about the next frontier that will happen if we're not only allowing the model to think harder, but also provide more tools. This is how real humans can solve those problems. For real humans, we don't ask them to solve Riemann hypothesis just with a piece of pen and paper. Yeah. So, with all the basic web browsing, search engine, and coding interpreters, that builds the foundations and the best reasoning model, builds the foundations for the Grok agent to come. So today we're actually introducing a new product called DeepSearch that is the first generation of our Grok agents that not just helping the engineers and researchers and scientists to do coding, but actually help everyone to answer questions that you have day to day. It's kind of like a next generation search engine that really helps you to understand the universe. So you can start asking questions like, for example, hey, when is the next Starship launch date, for example. So let's try that, hit answer. On the left hand side we see a high level progress bar, essentially the model knowledge knowledge knowledge knowledge knowledge knowledge you can see the bullet summaries of how the current model is doing, what website is browsing, what sources are verifying, and oftentimes actually cross-validate different sources out there to make sure the answer is actually correct before it's output final answer. And we can, at the same time, fire up a few more queries. How about, you know, you're a gamer, right? Sure. Yeah, so how about what are some of the best builds and most popular builds in Pathway XL? hardcore right a hardcore league if you can technically just look at the hardcore ladder might be a fast way to figure it out yeah we'll see what mono does um and then we can also do uh you know uh something more fun for example um how about like make a prediction about the march madness out there yeah so this is kind of a fun one where um warren buffett has a billion dollar bet if you can exactly match the i think I think the entire winning tree of Mosh Madness, you can win a billion dollars from Warren Buffett. So it would be pretty cool if AI could help you win a billion dollars from Buffett. That seems like a pretty good investment. Let's go. Yeah. All right, so now let's fire up the query and see what Moa does, so we can actually go back to our very first one. How about the- Buffett wasn't counting on this. Sorry. build a building a path of Excel hardcore right a hardcore league that are you can if you can't technically just look at the hardcore ladder be a fast way to figure it out yeah we'll see what model does and then we can also do you know something more fun for example So how about like make a prediction about the March Madness out there? Yeah, so this is kind of a fun one where Warren Buffett has a billion dollar bet. If you can... Let's see. Where it shows, you know, what are the subtasks. You can actually click the bottom left of this. Right. And then in this case, you can actually scroll through, actually reading through the mind of Grok. what information does the model actually think about are trustworthy, what are not, how does it actually cross-validate different information sources. So that makes the entire search experience and information retrieval process a lot more transparent to our users. And this is much more powerful than any search engine out there. You can literally just tell it, only use sources from X. It will try to respect that. And so it's much more steerable, much more intelligent. and then I mean it really should save you a lot of time so something that might take you half an hour or an hour of researching on the web or searching social media you can just ask it to go do that and and come back in 10 minutes later it's done an hour's worth of work for you that's really what it comes down to exactly and maybe better than you could have done it yourself yeah think about you have infinite amount of interns working for you now you can just fire up all the tasks and come back a minute later. So this is going to be an interesting one. March Madness had not happened yet. So I guess we have to follow up with a next live stream to new features. Roll this out. So the first question here is,